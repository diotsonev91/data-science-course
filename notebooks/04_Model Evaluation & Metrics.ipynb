{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "877c0f77-63b1-4277-8ea4-e2d3ad676b81",
   "metadata": {},
   "source": [
    "# Step 4. Model Evaluation & Metrics\n",
    "\n",
    "### In this step, we evaluate and compare our trained models (Custom CNN and MobileNetV2) to assess whether they meet the expectations of Hypothesis 1:\n",
    "> *\"A convolutional neural network (CNN) can accurately classify fruit images into 8 classes.\"*\n",
    "\n",
    "We perform the following evaluations:\n",
    "\n",
    "1. **Classification Report**\n",
    "   - Computes precision, recall, and F1-score for each fruit class.\n",
    "   - Helps us understand how well each model predicts individual categories.\n",
    "\n",
    "2. **Confusion Matrix**\n",
    "   - A matrix showing how often classes are correctly or incorrectly predicted.\n",
    "   - Reveals systematic misclassifications (e.g., between visually similar fruits).\n",
    "\n",
    "3. **Overall Accuracy**\n",
    "   - The percentage of correctly predicted images in the test set.\n",
    "   - Provides a straightforward benchmark for comparing models.\n",
    "\n",
    "4. **Learning Curves**\n",
    "   - Plots of training loss and validation accuracy over epochs.\n",
    "   - Allow us to compare convergence speed and detect overfitting/underfitting.\n",
    "\n",
    "These metrics provide insight into the **strengths and weaknesses of each approach** (lightweight custom CNN vs. pretrained MobileNetV2), and allow us to determine whether the models are suitable for real-world use or require further improvement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b97703d-1f55-4d59-8030-a15e698b8164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0 â€” Setup: import your module, set device, ensure result dirs\n",
    "import sys, os, re, json, torch\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "from models.mobileNetV2compare import (\n",
    "    TrainConfig,\n",
    "    run_mobilenet_v2_experiment\n",
    ")\n",
    "\n",
    "TRAIN_DIR = '../Dataset/Training'\n",
    "TEST_DIR  = '../Dataset/Test'\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "os.makedirs(\"../experiments/results\", exist_ok=True)\n",
    "os.makedirs(\"../experiments/plots\", exist_ok=True)\n",
    "\n",
    "def slugify(s): \n",
    "    return re.sub(r\"[^a-zA-Z0-9_-]+\", \"_\", s).strip(\"_\")\n",
    "\n",
    "# store preds for optional McNemar later\n",
    "pred_store = {}  # name -> {\"y_true\": np.array, \"y_pred\": np.array}\n",
    "prob_store = {}  # name -> np.array of probs (optional ECE later)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "160a9446-ff59-4319-80ef-183cb593242a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Custom CNN preds for 4 model(s).\n",
      "Loaded MobileNetV2 preds for 4 model(s).\n"
     ]
    }
   ],
   "source": [
    "# Cell 0b â€” Populate pred_store from disk (CNN + MobileNetV2)\n",
    "import json, os, re, numpy as np, torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from models.mobileNetV2compare import prepare_mobilenet_v2, get_mobilenet_loaders\n",
    "\n",
    "def slugify(s): \n",
    "    return re.sub(r\"[^a-zA-Z0-9_-]+\", \"_\", s).strip(\"_\")\n",
    "\n",
    "# 1) Load Custom CNN predictions saved in Step 3 JSON\n",
    "cnn_json_path = \"../experiments/results/custom_cnn_results.json\"\n",
    "if os.path.exists(cnn_json_path):\n",
    "    with open(cnn_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        cnn_data = json.load(f)\n",
    "    for name, d in cnn_data.items():\n",
    "        if \"y_true\" in d and \"y_pred\" in d:\n",
    "            pred_store[name] = {\n",
    "                \"y_true\": np.array(d[\"y_true\"]),\n",
    "                \"y_pred\": np.array(d[\"y_pred\"]),\n",
    "                \"class_names\": d.get(\"class_names\", None),\n",
    "            }\n",
    "            if \"y_prob\" in d:\n",
    "                prob_store[name] = np.array(d[\"y_prob\"])\n",
    "    print(f\"Loaded Custom CNN preds for {len([k for k in pred_store if 'MobileNetV2' not in k])} model(s).\")\n",
    "else:\n",
    "    print(\"[Info] custom_cnn_results.json not found; skipping CNN load.\")\n",
    "\n",
    "# 2) Recreate MobileNetV2 predictions from checkpoints (quick test inference)\n",
    "mnv2_specs = {\n",
    "    \"MobileNetV2 Grayscale MaxPool\":  {\"ckpt\":\"../experiments/runs/mnv2_gray_max.pt\",  \"input_type\":\"grayscale\", \"pooling\":\"max\"},\n",
    "    \"MobileNetV2 Grayscale Adaptive\": {\"ckpt\":\"../experiments/runs/mnv2_gray_adapt.pt\",\"input_type\":\"grayscale\", \"pooling\":\"adaptive\"},\n",
    "    \"MobileNetV2 RGB With Noise\":     {\"ckpt\":\"../experiments/runs/mnv2_rgb_noise.pt\", \"input_type\":\"rgb\",       \"pooling\":\"default\", \"use_noise\": True},\n",
    "    \"MobileNetV2 RGB Clean\":          {\"ckpt\":\"../experiments/runs/mnv2_rgb_clean.pt\", \"input_type\":\"rgb\",       \"pooling\":\"default\", \"use_noise\": False},\n",
    "}\n",
    "\n",
    "@torch.no_grad()\n",
    "def _get_preds(model, loader, device):\n",
    "    model.eval().to(device)\n",
    "    ys, yhat = [], []\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        logits = model(xb)\n",
    "        ys.append(yb.numpy())\n",
    "        yhat.append(logits.argmax(1).cpu().numpy())\n",
    "    import numpy as np\n",
    "    return np.concatenate(ys), np.concatenate(yhat)\n",
    "\n",
    "mnv2_loaded = 0\n",
    "for name, spec in mnv2_specs.items():\n",
    "    ckpt = spec[\"ckpt\"]\n",
    "    if not os.path.exists(ckpt):\n",
    "        print(f\"[Skip] Missing ckpt for {name}: {ckpt}\")\n",
    "        continue\n",
    "    use_noise = spec.get(\"use_noise\", False)\n",
    "    _, _, test_loader, _, in_ch = get_mobilenet_loaders(\n",
    "        TRAIN_DIR, TEST_DIR,\n",
    "        input_type=spec[\"input_type\"], use_noise=use_noise,\n",
    "        batch_size=32, val_split=0.2\n",
    "    )\n",
    "    class_names = getattr(test_loader.dataset, \"classes\", None)\n",
    "    num_classes = len(class_names) if class_names else 8\n",
    "\n",
    "    model = prepare_mobilenet_v2(\n",
    "        in_channels=in_ch, num_classes=num_classes, pooling=spec[\"pooling\"], pretrained=True\n",
    "    )\n",
    "    try:\n",
    "        state = torch.load(ckpt, map_location=device, weights_only=True)\n",
    "    except TypeError:\n",
    "        state = torch.load(ckpt, map_location=device)\n",
    "    model.load_state_dict(state, strict=False)\n",
    "\n",
    "    y_true, y_pred = _get_preds(model, test_loader, device)\n",
    "    pred_store[name] = {\n",
    "        \"y_true\": y_true,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"class_names\": class_names,\n",
    "    }\n",
    "    mnv2_loaded += 1\n",
    "\n",
    "print(f\"Loaded MobileNetV2 preds for {mnv2_loaded} model(s).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3512dde-2bad-46f9-be5c-9fbcf34359d2",
   "metadata": {},
   "source": [
    "#### Define evaluate_and_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d7b6927-c6c2-4316-872c-caec8a38ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 â€” Evaluation helper (JSON report + confusion matrix PNG)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_preds(model, loader, device=\"cpu\"):\n",
    "    model.eval().to(device)\n",
    "    y_true, y_pred, y_prob = [], [], []\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        logits = model(xb)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        y_true.append(yb.numpy())\n",
    "        y_pred.append(probs.argmax(1).cpu().numpy())\n",
    "        y_prob.append(probs.cpu().numpy())\n",
    "    return np.concatenate(y_true), np.concatenate(y_pred), np.concatenate(y_prob)\n",
    "\n",
    "def plot_confusion(cm, class_names, title, save_path):\n",
    "    fig, ax = plt.subplots(figsize=(6,5), dpi=130)\n",
    "    im = ax.imshow(cm, interpolation='nearest')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(range(len(class_names))); ax.set_xticklabels(class_names, rotation=45, ha=\"right\")\n",
    "    ax.set_yticks(range(len(class_names))); ax.set_yticklabels(class_names)\n",
    "    for i, j in product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        ax.text(j, i, f\"{cm[i,j]:.2f}\", ha=\"center\", va=\"center\", fontsize=7)\n",
    "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(save_path, bbox_inches=\"tight\"); plt.close(fig)\n",
    "\n",
    "def evaluate_and_save(model_name, model, test_loader, device=\"cpu\"):\n",
    "    # get class names directly from your ImageFolder\n",
    "    class_names = getattr(test_loader.dataset, \"classes\", [str(i) for i in range(model.classifier[1].out_features)])\n",
    "    y_true, y_pred, y_prob = get_preds(model, test_loader, device=device)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    rep = classification_report(y_true, y_pred, target_names=class_names, output_dict=True, zero_division=0)\n",
    "\n",
    "    cm_raw = confusion_matrix(y_true, y_pred, labels=range(len(class_names)))\n",
    "    cm_norm = cm_raw.astype(float) / cm_raw.sum(axis=1, keepdims=True).clip(min=1)\n",
    "\n",
    "    base = slugify(model_name)\n",
    "    out_json = f\"../experiments/results/{base}_report.json\"\n",
    "    with open(out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\n",
    "            \"model\": model_name,\n",
    "            \"accuracy\": acc,\n",
    "            \"classification_report\": rep,\n",
    "            \"confusion_matrix_raw\": cm_raw.tolist(),\n",
    "            \"confusion_matrix_norm\": cm_norm.tolist(),\n",
    "            \"class_names\": class_names\n",
    "        }, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    plot_confusion(cm_norm, class_names, f\"{model_name} â€” Confusion (norm.)\",\n",
    "                   f\"../experiments/plots/{base}_cm_norm.png\")\n",
    "\n",
    "    print(f\"[{model_name}] acc={acc:.4f} â†’ {out_json}\")\n",
    "    return y_true, y_pred, y_prob, acc, cm_raw, cm_norm, class_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b0274a-ba4d-4194-ad89-bd736d18d83f",
   "metadata": {},
   "source": [
    "### 4.1 Training MobileNetV2 Variants\n",
    "Here we fine-tune MobileNetV2 under four conditions:\n",
    "1. Grayscale + MaxPool  \n",
    "2. Grayscale + AdaptiveAvgPool  \n",
    "3. RGB with Noise (augmentation)  \n",
    "4. RGB Clean (no augmentation)  \n",
    "\n",
    "The goal is to compare these transfer learning results with our custom CNNs from Step 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f79e86b-d111-466d-8766-22a4715d2e4b",
   "metadata": {},
   "source": [
    "#### Train + evaluate: MobileNetV2 Grayscale MaxPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a841a42-993b-461c-9ac1-29998a39f971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | loss 0.4699 | val_acc 0.9780 | lr 0.001 | bs 8\n",
      "Epoch 2/10 | loss 0.1698 | val_acc 0.9890 | lr 0.001 | bs 8\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 â€” Train + Evaluate: MNV2 Grayscale MaxPool\n",
    "cfg = TrainConfig(epochs=10, lr=1e-3, batch_size=8, ckpt_path=\"../experiments/runs/mnv2_gray_max.pt\")\n",
    "test_acc, model, test_loader, hist_gray_max = run_mobilenet_v2_experiment(\n",
    "    train_dir=TRAIN_DIR, test_dir=TEST_DIR, num_classes=8,\n",
    "    cfg=cfg, input_type=\"grayscale\", pooling=\"max\",\n",
    "    experiment_name=\"MobileNetV2 Grayscale MaxPool\"\n",
    ")\n",
    "\n",
    "# evaluate + save report + confusion matrix + preds\n",
    "yt, yp, yprob, acc, cm_raw, cm_norm, class_names = evaluate_and_save(\n",
    "    \"MobileNetV2 Grayscale MaxPool\", model, test_loader, device=device\n",
    ")\n",
    "\n",
    "# store predictions/probabilities for later analysis\n",
    "pred_store[\"MobileNetV2 Grayscale MaxPool\"] = {\"y_true\": yt, \"y_pred\": yp, \"class_names\": class_names}\n",
    "prob_store[\"MobileNetV2 Grayscale MaxPool\"] = yprob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c0b38a-d4de-4cf7-87a0-becbc876b0cf",
   "metadata": {},
   "source": [
    "#### Train + evaluate: MobileNetV2 Grayscale Adaptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c96022-3250-426a-b006-30697f49b5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 â€” Train + Evaluate: MNV2 Grayscale Adaptive\n",
    "cfg = TrainConfig(epochs=10, lr=1e-3, batch_size=8, ckpt_path=\"../experiments/runs/mnv2_gray_adapt.pt\")\n",
    "test_acc, model, test_loader, hist_gray_adapt = run_mobilenet_v2_experiment(\n",
    "    train_dir=TRAIN_DIR, test_dir=TEST_DIR, num_classes=8,\n",
    "    cfg=cfg, input_type=\"grayscale\", pooling=\"adaptive\",\n",
    "    experiment_name=\"MobileNetV2 Grayscale Adaptive\"\n",
    ")\n",
    "\n",
    "# evaluate + save report + confusion matrix + preds\n",
    "yt, yp, yprob, acc, cm_raw, cm_norm, class_names = evaluate_and_save(\n",
    "    \"MobileNetV2 Grayscale Adaptive\", model, test_loader, device=device\n",
    ")\n",
    "\n",
    "# store predictions/probabilities for later analysis\n",
    "pred_store[\"MobileNetV2 Grayscale Adaptive\"] = {\"y_true\": yt, \"y_pred\": yp, \"class_names\": class_names}\n",
    "prob_store[\"MobileNetV2 Grayscale Adaptive\"] = yprob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046d75c9-25ee-4293-b4c4-f7bcb47794e9",
   "metadata": {},
   "source": [
    "#### Train + evaluate: MobileNetV2 RGB With Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd6789c-72c5-40ab-8775-328a17ba2e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 â€” Train + Evaluate: MNV2 RGB With Noise\n",
    "cfg = TrainConfig(epochs=10, lr=1e-3, batch_size=16, ckpt_path=\"../experiments/runs/mnv2_rgb_noise.pt\")\n",
    "test_acc, model, test_loader, hist_rgb_noise = run_mobilenet_v2_experiment(\n",
    "    train_dir=TRAIN_DIR, test_dir=TEST_DIR, num_classes=8,\n",
    "    cfg=cfg, input_type=\"rgb\", use_noise=True,\n",
    "    experiment_name=\"MobileNetV2 RGB With Noise\"\n",
    ")\n",
    "\n",
    "# evaluate + save report + confusion matrix + preds\n",
    "yt, yp, yprob, acc, cm_raw, cm_norm, class_names = evaluate_and_save(\n",
    "    \"MobileNetV2 RGB With Noise\", model, test_loader, device=device\n",
    ")\n",
    "\n",
    "# store predictions/probabilities for later analysis\n",
    "pred_store[\"MobileNetV2 RGB With Noise\"] = {\"y_true\": yt, \"y_pred\": yp, \"class_names\": class_names}\n",
    "prob_store[\"MobileNetV2 RGB With Noise\"] = yprob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e5b6a6-ddb3-48ae-ab8e-26e8be69c814",
   "metadata": {},
   "source": [
    "#### Train + evaluate: MobileNetV2 RGB Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e848406-8f58-40c5-a75c-da15cb97e5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 â€” Train + Evaluate: MNV2 RGB Clean\n",
    "cfg = TrainConfig(epochs=10, lr=1e-3, batch_size=16, ckpt_path=\"../experiments/runs/mnv2_rgb_clean.pt\")\n",
    "test_acc, model, test_loader, hist_rgb_clean = run_mobilenet_v2_experiment(\n",
    "    train_dir=TRAIN_DIR, test_dir=TEST_DIR, num_classes=8,\n",
    "    cfg=cfg, input_type=\"rgb\", use_noise=False,\n",
    "    experiment_name=\"MobileNetV2 RGB Clean\"\n",
    ")\n",
    "\n",
    "# evaluate + save artifacts + get per-sample preds/probs\n",
    "yt, yp, yprob, acc, cm_raw, cm_norm, class_names = evaluate_and_save(\n",
    "    \"MobileNetV2 RGB Clean\", model, test_loader, device=device\n",
    ")\n",
    "\n",
    "# store for plotting and stats later\n",
    "pred_store[\"MobileNetV2 RGB Clean\"] = {\"y_true\": yt, \"y_pred\": yp, \"class_names\": class_names}\n",
    "prob_store[\"MobileNetV2 RGB Clean\"] = yprob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cd3bd4-766e-436b-ade6-b3e3c22c98c0",
   "metadata": {},
   "source": [
    "#### Save MobileNetV2 histories JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc3c553-1274-4c30-8019-d1b05ae735c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 â€” Save MobileNetV2 histories for plotting\n",
    "mnv2_results = {\n",
    "    \"MobileNetV2 Grayscale MaxPool\":   {\"history\": {\"train_loss\": hist_gray_max[\"train_loss\"],   \"val_acc\": hist_gray_max[\"val_acc\"]}},\n",
    "    \"MobileNetV2 Grayscale Adaptive\":  {\"history\": {\"train_loss\": hist_gray_adapt[\"train_loss\"], \"val_acc\": hist_gray_adapt[\"val_acc\"]}},\n",
    "    \"MobileNetV2 RGB With Noise\":      {\"history\": {\"train_loss\": hist_rgb_noise[\"train_loss\"],  \"val_acc\": hist_rgb_noise[\"val_acc\"]}},\n",
    "    \"MobileNetV2 RGB Clean\":           {\"history\": {\"train_loss\": hist_rgb_clean[\"train_loss\"],  \"val_acc\": hist_rgb_clean[\"val_acc\"]}},\n",
    "}\n",
    "with open(\"../experiments/results/mobilenetv2_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(mnv2_results, f, ensure_ascii=False, indent=2)\n",
    "print(\"Saved â†’ ../experiments/results/mobilenetv2_results.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacb4c7a-65d6-4d1c-9d48-a2f415d8b2aa",
   "metadata": {},
   "source": [
    "### 4.2 Plot learning curves overlay (Custom CNN + MobileNetV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8b8ab1-e078-49b7-8e39-8f4bb357af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 â€” Plot learning curves overlay (CNN + MobileNetV2; schema-aware)\n",
    "import json, matplotlib.pyplot as plt\n",
    "\n",
    "def load_histories(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def extract_curves(entry):\n",
    "    \"\"\"\n",
    "    Supports both schemas:\n",
    "      - Step 4 (MNV2): {\"history\": {\"train_loss\": [...], \"val_acc\": [...]} }\n",
    "      - Step 3 (CNN) : {\"train_losses\": [...], \"val_accuracies\": [...]} (+ other fields)\n",
    "    Returns (train_loss_list, val_acc_list).\n",
    "    \"\"\"\n",
    "    h = entry.get(\"history\")\n",
    "    if isinstance(h, dict):\n",
    "        return h.get(\"train_loss\", []), h.get(\"val_acc\", [])\n",
    "    return entry.get(\"train_losses\", []), entry.get(\"val_accuracies\", [])\n",
    "\n",
    "def plot_histories(paths):\n",
    "    fig1, ax1 = plt.subplots(figsize=(6,4), dpi=130)\n",
    "    fig2, ax2 = plt.subplots(figsize=(6,4), dpi=130)\n",
    "\n",
    "    for p in paths:\n",
    "        data = load_histories(p)\n",
    "        for name, d in data.items():\n",
    "            tl, va = extract_curves(d)\n",
    "            if tl: ax1.plot(tl, label=name)\n",
    "            if va: ax2.plot(va, label=name)\n",
    "\n",
    "    ax1.set_title(\"Training Loss (All Models)\")\n",
    "    ax1.set_xlabel(\"Epoch\"); ax1.set_ylabel(\"Loss\"); ax1.legend(fontsize=7)\n",
    "\n",
    "    ax2.set_title(\"Validation Accuracy (All Models)\")\n",
    "    ax2.set_xlabel(\"Epoch\"); ax2.set_ylabel(\"Acc\"); ax2.legend(fontsize=7)\n",
    "\n",
    "    fig1.tight_layout(); fig2.tight_layout()\n",
    "    fig1.savefig(\"../experiments/plots/learning_curves_loss.png\", bbox_inches=\"tight\")\n",
    "    fig2.savefig(\"../experiments/plots/learning_curves_valacc.png\", bbox_inches=\"tight\")\n",
    "\n",
    "    # show inline\n",
    "    plt.show()  # shows both current figures\n",
    "\n",
    "    plt.close(fig1); plt.close(fig2)\n",
    "    print(\"Saved â†’ learning_curves_loss.png & learning_curves_valacc.png\")\n",
    "\n",
    "plot_histories([\n",
    "    \"../experiments/results/custom_cnn_results.json\",     # Step 3 (CNNs)\n",
    "    \"../experiments/results/mobilenetv2_results.json\"     # Step 4 (MNV2)\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804c7a9a-b782-479e-a728-b5fcf6a08d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9b â€” Show confusion matrices for ALL models in pred_store (CNN + MobileNetV2)\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "if not pred_store:\n",
    "    print(\"pred_store is empty. Run Cell 0b to populate it first.\")\n",
    "else:\n",
    "    for name, bundle in pred_store.items():\n",
    "        y_true = bundle[\"y_true\"]\n",
    "        y_pred = bundle[\"y_pred\"]\n",
    "        labels = bundle.get(\"class_names\", None)\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=range(len(labels)) if labels else None)\n",
    "        disp = ConfusionMatrixDisplay(cm, display_labels=labels if labels else None)\n",
    "        disp.plot(cmap=\"Blues\", xticks_rotation=45)\n",
    "        plt.title(f\"Confusion Matrix â€” {name}\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f199da3d-cb54-49ef-9e52-b5e3d8a0a337",
   "metadata": {},
   "source": [
    "### 4.3 Aggregate comparison table (accuracy/F1/size/latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fb4887-e0e6-4fa5-b296-d095e20859f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8 â€” Build comparison CSV from CNN + MobileNetV2 reports\n",
    "import json, os, pandas as pd, time\n",
    "\n",
    "def macro_weighted_f1(report_dict):\n",
    "    if not report_dict:\n",
    "        return None, None\n",
    "    return (\n",
    "        report_dict.get(\"macro avg\", {}).get(\"f1-score\"),\n",
    "        report_dict.get(\"weighted avg\", {}).get(\"f1-score\"),\n",
    "    )\n",
    "\n",
    "def model_disk_size(path):\n",
    "    return os.path.getsize(path) / (1024**2) if path and os.path.exists(path) else float(\"nan\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "# --- 1) Load Custom CNN results from Step 3 JSON ---\n",
    "cnn_json_path = \"../experiments/results/custom_cnn_results.json\"\n",
    "if os.path.exists(cnn_json_path):\n",
    "    with open(cnn_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        cnn_data = json.load(f)\n",
    "    for name, d in cnn_data.items():\n",
    "        rows.append({\n",
    "            \"model\": name,\n",
    "            \"family\": \"Custom CNN\",\n",
    "            \"accuracy\": d.get(\"test_accuracy\"),\n",
    "            \"macro_f1\": None,        # filled only if you re-evaluate CNNs with evaluate_and_save\n",
    "            \"weighted_f1\": None,\n",
    "            \"ckpt_size_mb\": model_disk_size(d.get(\"ckpt\"))\n",
    "        })\n",
    "\n",
    "# --- 2) Load MobileNetV2 reports (Step 4) ---\n",
    "mnv2_names = [\n",
    "    \"MobileNetV2 Grayscale MaxPool\",\n",
    "    \"MobileNetV2 Grayscale Adaptive\",\n",
    "    \"MobileNetV2 RGB With Noise\",\n",
    "    \"MobileNetV2 RGB Clean\",\n",
    "]\n",
    "\n",
    "name_to_ckpt = {\n",
    "    \"MobileNetV2 Grayscale MaxPool\":  \"../experiments/runs/mnv2_gray_max.pt\",\n",
    "    \"MobileNetV2 Grayscale Adaptive\": \"../experiments/runs/mnv2_gray_adapt.pt\",\n",
    "    \"MobileNetV2 RGB With Noise\":     \"../experiments/runs/mnv2_rgb_noise.pt\",\n",
    "    \"MobileNetV2 RGB Clean\":          \"../experiments/runs/mnv2_rgb_clean.pt\",\n",
    "}\n",
    "\n",
    "for n in mnv2_names:\n",
    "    report_path = f\"../experiments/results/{slugify(n)}_report.json\"\n",
    "    if not os.path.exists(report_path):\n",
    "        print(\"Missing:\", report_path)\n",
    "        continue\n",
    "    with open(report_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        rep = json.load(f)\n",
    "\n",
    "    acc = rep[\"accuracy\"]\n",
    "    macro_f1, weighted_f1 = macro_weighted_f1(rep.get(\"classification_report\", {}))\n",
    "    size_mb = model_disk_size(name_to_ckpt.get(n, \"\"))\n",
    "\n",
    "    rows.append({\n",
    "        \"model\": n,\n",
    "        \"family\": \"MobileNetV2\",\n",
    "        \"accuracy\": acc,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"weighted_f1\": weighted_f1,\n",
    "        \"ckpt_size_mb\": size_mb\n",
    "    })\n",
    "\n",
    "# --- 3) Build DataFrame ---\n",
    "df = pd.DataFrame(rows).sort_values(by=[\"accuracy\"], ascending=False)\n",
    "out_csv = \"../experiments/results/model_comparison_all.csv\"\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(\"Saved â†’\", out_csv)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88cefd8-cc80-4663-bf7c-11476b4a4fb6",
   "metadata": {},
   "source": [
    "### 4.3 McNemar significance test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0314d2-efb9-40c1-806e-4f289f11949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9 â€” McNemar across ALL models (Custom CNN + MobileNetV2)\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "import numpy as np, os, json, re, torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from models.mobileNetV2compare import prepare_mobilenet_v2, get_mobilenet_loaders\n",
    "\n",
    "from models.cnn_small import create_fruit_cnn\n",
    "# --- Paths / globals you already have ---\n",
    "TRAIN_DIR = '../Dataset/Training'\n",
    "TEST_DIR  = '../Dataset/Test'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Reuse existing pred_store if present; else create\n",
    "try:\n",
    "    pred_store\n",
    "except NameError:\n",
    "    pred_store = {}\n",
    "\n",
    "# ---------- Utilities ----------\n",
    "def slugify(s): return re.sub(r\"[^a-zA-Z0-9_-]+\", \"_\", s).strip(\"_\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def _get_preds(model, loader, device):\n",
    "    model.eval().to(device)\n",
    "    y_true, y_pred = [], []\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        logits = model(xb)\n",
    "        y_true.append(yb.numpy())\n",
    "        y_pred.append(logits.argmax(1).cpu().numpy())\n",
    "    return np.concatenate(y_true), np.concatenate(y_pred)\n",
    "\n",
    "def _make_cnn_test_loader(input_type, img_size=(100,100), batch_size=32, use_noise=False):\n",
    "    if input_type == \"grayscale\":\n",
    "        tfm = transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "            transforms.Resize(img_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "        ])\n",
    "    else:\n",
    "        tfm = transforms.Compose([\n",
    "            transforms.Resize(img_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5]*3, std=[0.5]*3),\n",
    "        ])\n",
    "    ds = ImageFolder(TEST_DIR, transform=tfm)\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True), ds.classes\n",
    "\n",
    "def _infer_cnn_spec_from_name(name, in_channels):\n",
    "    input_type = \"grayscale\" if in_channels == 1 else \"rgb\"\n",
    "    pooling = \"max\"\n",
    "    if \"Adaptive\" in name or \"AdaptiveAvgPool\" in name:\n",
    "        pooling = \"adaptive\"\n",
    "    # (Optional noise flag, if you encoded it in the name)\n",
    "    use_noise = \"With Noise\" in name or \"Noise\" in name\n",
    "    return dict(input_type=input_type, pooling=pooling, use_noise=use_noise)\n",
    "\n",
    "# Known MobileNetV2 experiment specs & ckpts\n",
    "mnv2_specs = {\n",
    "    \"MobileNetV2 Grayscale MaxPool\":  {\"ckpt\":\"../experiments/runs/mnv2_gray_max.pt\",  \"input_type\":\"grayscale\", \"pooling\":\"max\"},\n",
    "    \"MobileNetV2 Grayscale Adaptive\": {\"ckpt\":\"../experiments/runs/mnv2_gray_adapt.pt\",\"input_type\":\"grayscale\", \"pooling\":\"adaptive\"},\n",
    "    \"MobileNetV2 RGB With Noise\":     {\"ckpt\":\"../experiments/runs/mnv2_rgb_noise.pt\", \"input_type\":\"rgb\",       \"pooling\":\"default\"},\n",
    "    \"MobileNetV2 RGB Clean\":          {\"ckpt\":\"../experiments/runs/mnv2_rgb_clean.pt\", \"input_type\":\"rgb\",       \"pooling\":\"default\"},\n",
    "}\n",
    "\n",
    "# Load CNN JSON once to know names/ckpts/in_channels\n",
    "cnn_json_path = \"../experiments/results/custom_cnn_results.json\"\n",
    "cnn_results = {}\n",
    "if os.path.exists(cnn_json_path):\n",
    "    with open(cnn_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        cnn_results = json.load(f)\n",
    "\n",
    "def ensure_preds(model_name):\n",
    "    \"\"\"Return (y_true, y_pred) for any model name; rebuild+load if needed, then cache in pred_store.\"\"\"\n",
    "    if model_name in pred_store:\n",
    "        return pred_store[model_name][\"y_true\"], pred_store[model_name][\"y_pred\"]\n",
    "\n",
    "    # Case 1: MobileNetV2\n",
    "    if model_name in mnv2_specs:\n",
    "        spec = mnv2_specs[model_name]\n",
    "        # Build test loader via your helper\n",
    "        _, _, test_loader, _, in_channels = get_mobilenet_loaders(\n",
    "            TRAIN_DIR, TEST_DIR,\n",
    "            input_type=spec[\"input_type\"], use_noise=(\"Noise\" in model_name),\n",
    "            batch_size=32, val_split=0.2  # val_split doesn't affect test_loader content\n",
    "        )\n",
    "        # Build model and load ckpt\n",
    "        # Get num_classes from dataset\n",
    "        cls_names = getattr(test_loader.dataset, \"classes\", None)\n",
    "        num_classes = len(cls_names) if cls_names else 8\n",
    "        model = prepare_mobilenet_v2(in_channels=in_channels, num_classes=num_classes, pooling=spec[\"pooling\"], pretrained=True)\n",
    "        if os.path.exists(spec[\"ckpt\"]):\n",
    "            state = torch.load(spec[\"ckpt\"], map_location=device)\n",
    "            model.load_state_dict(state)\n",
    "        y_true, y_pred = _get_preds(model, test_loader, device)\n",
    "        pred_store[model_name] = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "        return y_true, y_pred\n",
    "\n",
    "    # Case 2: Custom CNN (from Step 3 JSON)\n",
    "    if model_name in cnn_results:\n",
    "        entry = cnn_results[model_name]\n",
    "        ckpt = entry.get(\"ckpt\")\n",
    "        in_ch = entry.get(\"in_channels\", 3)\n",
    "        spec = _infer_cnn_spec_from_name(model_name, in_ch)\n",
    "\n",
    "        test_loader, class_names = _make_cnn_test_loader(spec[\"input_type\"])\n",
    "        num_classes = len(class_names) if class_names else 8\n",
    "\n",
    "        # ðŸ” Build your small CNN the same way you trained it\n",
    "        model = create_fruit_cnn(pooling=spec[\"pooling\"], in_channels=in_ch, num_classes=num_classes)\n",
    "        if ckpt and os.path.exists(ckpt):\n",
    "            state = torch.load(ckpt, map_location=device)\n",
    "            model.load_state_dict(state)\n",
    "\n",
    "        y_true, y_pred = _get_preds(model, test_loader, device)\n",
    "        pred_store[model_name] = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "        return y_true, y_pred\n",
    "\n",
    "    raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "\n",
    "def mcnemar_test(y_true, y_pred_A, y_pred_B):\n",
    "    A_correct = (y_pred_A == y_true)\n",
    "    B_correct = (y_pred_B == y_true)\n",
    "    b = int(np.sum( ( A_correct) & (~B_correct)))\n",
    "    c = int(np.sum( (~A_correct) & ( B_correct)))\n",
    "    table = [[0, b], [c, 0]]\n",
    "    res = mcnemar(table, exact=True)\n",
    "    return {\"b\": b, \"c\": c, \"p_value\": float(res.pvalue)}\n",
    "\n",
    "# -------- Choose what to compare --------\n",
    "# Option 1: pick manually\n",
    "# A = \"MobileNetV2 RGB Clean\"\n",
    "# B = \"Grayscale AdaptiveAvgPool\"   # example custom CNN name from your JSON\n",
    "\n",
    "# Option 2: auto-pick best CNN vs best MNV2 by accuracy\n",
    "def _best_names():\n",
    "    # best CNN\n",
    "    best_cnn, best_cnn_acc = None, -1\n",
    "    for name, d in cnn_results.items():\n",
    "        acc = d.get(\"test_accuracy\", -1)\n",
    "        if acc is not None and acc > best_cnn_acc:\n",
    "            best_cnn, best_cnn_acc = name, acc\n",
    "    # best MNV2 (from saved reports)\n",
    "    mnv2_best, mnv2_best_acc = None, -1\n",
    "    for n in mnv2_specs.keys():\n",
    "        rpath = f\"../experiments/results/{slugify(n)}_report.json\"\n",
    "        if os.path.exists(rpath):\n",
    "            with open(rpath, \"r\", encoding=\"utf-8\") as f:\n",
    "                rep = json.load(f)\n",
    "            acc = rep.get(\"accuracy\", -1)\n",
    "            if acc > mnv2_best_acc:\n",
    "                mnv2_best, mnv2_best_acc = n, acc\n",
    "    return best_cnn, mnv2_best\n",
    "\n",
    "A, B = _best_names()  # auto-pick\n",
    "print(f\"Comparing:\\n  A = {A}\\n  B = {B}\")\n",
    "\n",
    "# -------- Run McNemar --------\n",
    "y_true_A, y_pred_A = ensure_preds(A)\n",
    "y_true_B, y_pred_B = ensure_preds(B)\n",
    "assert np.array_equal(y_true_A, y_true_B), \"Test sets must match\"\n",
    "stats = mcnemar_test(y_true_A, y_pred_A, y_pred_B)\n",
    "print(f\"McNemar {A} vs {B} â†’ b={stats['b']} c={stats['c']} p={stats['p_value']:.4g}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8770ab4e-0a77-4006-af31-afb4480df036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea7f1e8-327c-4bc4-819b-1d1a1b267ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b056276-4339-4833-8eaa-f1cdf4b52915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
