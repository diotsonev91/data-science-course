# Fruit Classification â€” Data Science Course Project

This repository contains my course project for fruit image classification using **Convolutional Neural Networks (CNNs)**.  
The work explores **grayscale vs. RGB** inputs, **max vs. average pooling**, and prepares the model for **quantization** and **edge deployment**.

---

## ğŸ“¦ Dataset

- **Fruits 360** (Kaggle). Images are 100Ã—100, foldered by class and suitable for `torchvision.datasets.ImageFolder`.
- In the project we use a reduced subset of 8 classes, convert to **grayscale** for the baseline, and apply **light augmentations** on the training set only.

> You should place the dataset like this:
```
Dataset/
â”œâ”€ Training/
â”‚   â”œâ”€ ClassA/  image1.jpg ...
â”‚   â”œâ”€ ClassB/  ...
â””â”€ Test/
    â”œâ”€ ClassA/  ...
    â”œâ”€ ClassB/  ...
```

---

## ğŸ—‚ Repository Structure

```
data-science-course/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ index.ipynb                  # project overview & navigation
â”‚   â”œâ”€â”€ 01_eda.ipynb                 # class distribution, sanity checks
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb       # transforms, loaders, class weights
â”‚   â”œâ”€â”€ 03_train_cnn.ipynb           # baseline CNN + variants & comparison
â”‚   â”œâ”€â”€ 04_eval_mobilenetv2.ipynb    # (optional) MobileNetV2 comparison
â”‚   â”œâ”€â”€ 05_results.ipynb             # final metrics & visualization
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data.py                      # transforms, dataloaders, class weights, EDA helpers
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ cnn_small.py             # compact CNN, max/avg pooling, 1/3 channels
â”‚   â”œâ”€â”€ train.py                     # training loop, early stopping, test eval
â”‚   â””â”€â”€ viz.py                       # plots, misclassified viewer, curves
â”‚
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ figures/                     # generated plots saved here
â”‚
â”œâ”€â”€ environment.yml                  # full Conda environment (portable version)
â”œâ”€â”€ requirements.txt                 # lightweight pip install (CPU-friendly)
â””â”€â”€ README.md                        # this file
```

---

## âš™ï¸ Environment Setup (choose ONE)

### Option A â€” Conda (full stack)
> Recommended on desktops/servers. On lowâ€‘RAM laptops Conda can be slow; use Option B instead.

```bash
conda env create -f environment.yml
conda activate ds_project
python -m ipykernel install --user --name=ds_project --display-name "Python (ds_project)"
```

**Notes**
- `environment.yml` is written to be crossâ€‘platform (Windows/Linux).  
- If dependency solving is slow, install the faster solver:
  ```bash
  conda install -n base conda-libmamba-solver -c conda-forge -y
  conda config --set solver libmamba
  conda env create -f environment.yml
  ```
- If you see `ResolvePackageNotFound` for platform-specific builds or a `prefix:` path in a thirdâ€‘party file, remove the `prefix:` line and any `=py311hXXXX_0` build IDs.

### Option B â€” Lightweight pip (works great on laptops)
```bash
python3 -m venv .venv
source .venv/bin/activate        # Windows: .venv\Scripts\activate
python -m pip install --upgrade pip
pip install -r requirements.txt
python -m ipykernel install --user --name=ds_project --display-name "Python (ds_project)"
```

This installs the **CPU** version of PyTorch by default.

### Option C â€” GPU (desktop with NVIDIA)
Use Conda and replace `cpuonly` with:
```yaml
channels: [pytorch, nvidia, conda-forge, defaults]
dependencies:
  - pytorch=2.5.*
  - torchvision=0.20.*
  - torchaudio=2.5.*
  - pytorch-cuda=12.4
  # ...rest of stack
```
Or with pip:
```bash
pip install torch==2.5.*+cu124 torchvision==0.20.*+cu124 torchaudio==2.5.*   -f https://download.pytorch.org/whl/torch_stable.html
```

---

## ğŸš€ Quick Start

1. **Create environment** using Option A or B above.
2. **Launch Jupyter**:
   ```bash
   jupyter lab
   ```
3. Open `notebooks/index.ipynb` and follow the links:
   - `01_eda.ipynb` â€” dataset sanity checks & class distribution
   - `02_preprocessing.ipynb` â€” transforms, loaders (train/val/test), class weights
   - `03_train_cnn.ipynb` â€” baseline CNN (grayscale), misclassifications, variants (avg pooling, RGB)
   - `05_results.ipynb` â€” comparison plots via `results_summary`

> Figures are saved automatically under `reports/figures/`.

---

## ğŸ§ª Reproducibility

- We seed all randomness (`numpy`, `torch`, `DataLoader` generators, worker seeds).  
- On GPU, some ops (e.g., `AdaptiveAvgPool2d` backward) can be nonâ€‘deterministic; our â€œadaptiveâ€ variant uses deterministic `AvgPool2d` instead for exact reproducibility.
- For Windows, `num_workers=0` avoids spawn/pickling issues; increase if needed.

Minimal example in notebooks:
```python
from data import make_dataloaders
train_loader, val_loader, test_loader, class_weights, class_names, in_ch = make_dataloaders(
    "Dataset/Training", "Dataset/Test",
    batch_size=32, val_split=0.2, img_size=100,
    num_workers=0, seed=42, mode="grayscale", verbose=True
)
```

---

## ğŸ§± Experiments Overview

- **Baseline (Grayscale, MaxPool)**: compact CNN, 1 input channel, classâ€‘weighted loss.  
- **Pooling Variant (AvgPool)**: deterministic average pooling vs max pooling.  
- **RGB Variants**: with/without light noise (blur + erasing); `in_channels=3`.  
- **Misclassified Viewer**: quick inspection of typical errors.  
- **Results Summary**: each experiment logs curves & test accuracy to `results_summary` and saves a plot.

Saved model weights (e.g., `fruit_cnn_baseline_with_val.pth`) are written to the project root unless changed.

---

## ğŸ›  Troubleshooting

- **Conda solve is slow / gets â€œKilledâ€**  
  Use the faster solver or micromamba:
  ```bash
  conda install -n base conda-libmamba-solver -c conda-forge -y
  conda config --set solver libmamba
  # or: micromamba create -n ds_project -f environment.yml -y
  ```

- **Bad channel URL like `https//conda.anaconda.org/...`**  
  Fix `.condarc`:
  ```bash
  conda config --remove-key channels
  conda config --add channels pytorch
  conda config --add channels conda-forge
  conda config --add channels defaults
  conda clean -a -y
  ```

- **`environment.yml` has `prefix:` or Windowsâ€‘only build hashes**  
  Delete `prefix:` and avoid build pins; or export cleanly next time:
  ```bash
  conda env export --from-history > environment.yml
  # or
  conda env export --no-builds > environment.yml
  ```

- **Restore the committed environment file**  
  ```bash
  git restore environment.yml
  # if staged:
  git restore --staged environment.yml && git restore environment.yml
  ```

- **Jupyter uses the wrong interpreter**  
  Reâ€‘register the kernel **from the active env**:
  ```bash
  python -m ipykernel install --user --name=ds_project --display-name "Python (ds_project)"
  ```

---

## ğŸ‘©â€ğŸ« Notes for the Instructor

- If Conda is problematic on your machine, please use `requirements.txt`:
  ```bash
  python3 -m venv .venv
  source .venv/bin/activate
  pip install -r requirements.txt
  ```
- Project targets **Python 3.11**, **PyTorch 2.5**, and a standard DS stack.  
- Reproducibility is enforced with fixed seeds; figures are saved to `reports/figures/`.

---

## ğŸ“„ License

MIT â€” feel free to use and adapt for educational purposes.
